# An unique identifier for the head node and workers of this cluster.
cluster_name: minimal

idle_timeout_minutes: 1

# Cloud-provider specific configuration.
provider:
    type: aws
    region: ap-northeast-1
    cache_stopped_nodes: False # terminate ec2 when dropped

docker:
    image: "rayproject/ray:latest"
    # rayproject/ray-ml:latest-gpu: CUDA support, includes ML dependencies.
    # rayproject/ray:latest-gpu: CUDA support, no ML dependencies.
    # rayproject/ray-ml:latest: No CUDA support, includes ML dependencies.
    # rayproject/ray:latest: No CUDA support, no ML dependencies.
    container_name: "ray_container"

auth:
    ssh_user: ubuntu

available_node_types:
    ray.head.default:
        resources: {}
        node_config:
            InstanceType: m5.large
            ImageId: ami-088da9557aae42f39
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 100
            KeyName: ray-autoscaler_ap-northeast-1
    ray.worker.default:
        min_workers: 0
        max_workers: 2
        resources: {}
        node_config:
            InstanceType: m5.large
            ImageId: ami-088da9557aae42f39
            InstanceMarketOptions:
                MarketType: spot
            KeyName: ray-autoscaler_ap-northeast-1

setup_commands: []
#   - pip install tensorflow # if your job use tensorflow
initialization_commands:
    - curl -fsSL https://get.docker.com -o get-docker.sh
    - sudo sh get-docker.sh
    - sudo usermod -aG docker $USER
    - sudo systemctl restart docker -f
